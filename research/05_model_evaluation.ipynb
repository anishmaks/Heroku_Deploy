{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Sasu4\\\\SHIP_Classification_using_Resnet\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Sasu4\\\\SHIP_Classification_using_Resnet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    params_classes: int\n",
    "    CLASS_NAMES:list\n",
    "    \n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_include_top: bool\n",
    "    params_weights: str\n",
    "    params_classes: int\n",
    "    freeze_all: bool\n",
    "    freeze_till: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "  def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model=None\n",
    "        self.optimizer = None  # Initialize as needed\n",
    "        self.loss_fn = None  # Initialize as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch \n",
    "\n",
    "# Load the entire model\n",
    "model = torch.load(\"artifacts/training/model.pth\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ship_Classifier.constants import *\n",
    "from Ship_Classifier.utils.common import read_yaml,create_directories\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.CLASS_NAMES=['Cargo', 'Cruise', 'Carrier', 'Military', 'Tanker']\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_validation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "        path_of_model=Path(\"artifacts/training/model.pth\"),  # Updated model path to PyTorch format\n",
    "        training_data=Path(\"artifacts/data_ingestion/extracted_data/Images\"),  # Update path to your training images\n",
    "        all_params=self.params,\n",
    "        params_image_size=self.params.IMAGE_SIZE,\n",
    "        params_batch_size=self.params.BATCH_SIZE,\n",
    "        CLASS_NAMES=['Cargo', 'Cruise', 'Carrier', 'Military', 'Tanker'],  # Add class names\n",
    "        params_classes=self.params.CLASSES\n",
    "    )\n",
    "        return eval_config   \n",
    "    \n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from torchvision import transforms, datasets,models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ship_Classifier import config\n",
    "from Ship_Classifier.utils.common import save_json\n",
    "from Ship_Classifier.components.prepare_base_model import PrepareBaseModel\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def _valid_loader(self):\n",
    "        # Define transformations\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(self.config.params_image_size[:-1]),  # Resize images to the desired size\n",
    "            transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "        ])\n",
    "\n",
    "        # Load validation dataset\n",
    "        validation_dataset = datasets.ImageFolder(\n",
    "            root=self.config.training_data,  # Path to the validation data\n",
    "            transform=transform\n",
    "        )\n",
    "        # Display the number of images in each folder (class)\n",
    "        class_counts = {class_name: 0 for class_name in validation_dataset.classes}\n",
    "        for _, label in validation_dataset:\n",
    "            class_name = validation_dataset.classes[label]\n",
    "            class_counts[class_name] += 1\n",
    "        \n",
    "        for class_name, count in class_counts.items():\n",
    "            print(f\"Found {count} images belonging to class '{class_name}'\")\n",
    "\n",
    "        # Create data loader\n",
    "        self.valid_loader = DataLoader(\n",
    "            validation_dataset,\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: str,params_classes:int) -> nn.Module:\n",
    "        # Load the saved PyTorch model\n",
    "        model=models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, params_classes)\n",
    "       \n",
    "        state_dict = torch.load(path)\n",
    "        # Load the state dictionary into the model\n",
    "        model.load_state_dict( state_dict)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        return model\n",
    "\n",
    "    def evaluation(self):\n",
    "        # Load the model\n",
    "        self.model = self.load_model(self.config.path_of_model,self.config.params_classes).to(self.device)\n",
    "\n",
    "        # Prepare the validation data loader\n",
    "        self._valid_loader()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Set up evaluation metrics\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "\n",
    "        # Evaluate the model\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate average loss and accuracy\n",
    "        self.average_loss = total_loss / len(self.valid_loader.dataset)\n",
    "        self.accuracy = correct_predictions / len(self.valid_loader.dataset)\n",
    "\n",
    "        self.score = {\"loss\": self.average_loss, \"accuracy\": self.accuracy}\n",
    "\n",
    "    def save_score(self):\n",
    "        \n",
    "        \n",
    "        # Save the scores as a JSON file\n",
    "        save_json(path=Path(\"scores.json\"), data=self.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-27 19:17:54,220: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-08-27 19:17:54,224: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-27 19:17:54,226: INFO: common: created directory at: artifacts]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sasu4\\AppData\\Local\\Temp\\ipykernel_31632\\2995088565.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 images belonging to class 'Cargo'\n",
      "Found 106 images belonging to class 'Carrier'\n",
      "Found 108 images belonging to class 'Cruise'\n",
      "Found 108 images belonging to class 'Military'\n",
      "Found 118 images belonging to class 'Tanker'\n",
      "[2024-08-27 19:18:34,825: INFO: common: json file saved at: scores.json]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize the configuration manager\n",
    "    config = ConfigurationManager()\n",
    "\n",
    "    # Get the validation configuration\n",
    "    val_config = config.get_validation_config()\n",
    "\n",
    "    # Create an Evaluation instance with the validation configuration\n",
    "    evaluation = Evaluation(val_config)\n",
    "\n",
    "    # Perform the evaluation\n",
    "    evaluation.evaluation()\n",
    "\n",
    "    # Save the evaluation score\n",
    "    evaluation.save_score()\n",
    "\n",
    "except Exception as e:\n",
    "    # Raise the exception if any errors occur\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
